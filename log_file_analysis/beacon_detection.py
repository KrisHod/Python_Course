# Sometimes we are interested in patters between logs. 
# For instance C2 traffic typically has characteristics the differentiate it from normal traffic. 
# C2, short for Command and Control, represents a communication channel established by attackers to remotely control compromised computer systems or devices. 
# This channel typically persists over a long period of time and has periodic communication.
# To idenfify C2 traffic we look at HTTP logs and connection logs. The connection log is used to identify connections that have a long duration. 
# The HTTP logs are used to identify periodic or frequent communication.
# These logs files are both generated by Zeek and can be connected using their UID. 
# The UID field serves as a unique identifier for network connections or network events observed by Zeek.

import re, json
from datetime import datetime as dt
from collections import Counter
from operator import itemgetter
from log_analyzer import openLogFile

def parseZeekConn(log_entry):
    log_data = re.split("\t", log_entry.rstrip())
    r = {}
    r["ts"] = dt.fromtimestamp(float(log_data[0]))
    r["uid"] = log_data[1]
    r["src_ip"] = log_data[2]
    r["src_port"] = log_data[3]
    r["dst_ip"] = log_data[4]
    r["dst_port"] = log_data[5]
    r["proto"] = log_data[6]
    r["service"] = log_data[7]
    r["duration"] = log_data[8]
    r["src_bytes"] = log_data[9]
    r["dst_bytes"] = log_data[10]
    r["conn_state"] = log_data[11]
    r["local_src"] = log_data[12]
    r["local_rsp"] = log_data[13]
    r["missed_bytes"] = log_data[14]
    r["history"] = log_data[15]
    r["srk_pkts"] = log_data[16]
    r["src_ip_bytes"] = log_data[17]
    r["dst_pkts"] = log_data[18]
    r["dst_ip_bytes"] = log_data[19]
    r["tunnel_parents"] = log_data[20]
    return r

def parseZeekHttp(log_entry):
    log_data = re.split("\t", log_entry.rstrip())
    r = {}
    r["ts"] = dt.fromtimestamp(float(log_data[0]))
    r["uid"] = log_data[1]
    r["src_ip"] = log_data[2]
    r["src_port"] = log_data[3]
    r["dst_ip"] = log_data[4]
    r["dst_port"] = log_data[5]
    r["trans_depth"] = log_data[6]
    r["method"] = log_data[7]
    r["host"] = log_data[8]
    r["uri"] = log_data[9]
    r["referrer"] = log_data[10]
    r["version"] = log_data[11]
    r["user_agent"] = log_data[12]
    r["origin"] = log_data[13]
    r["request_body_len"] = log_data[14]
    r["response_body_len"] = log_data[15]
    r["status_code"] = log_data[16]
    r["status_msg"] = log_data[17]
    r["info_code"] = log_data[18]
    r["info_msg"] = log_data[19]
    r["tags"] = log_data[20]
    r["username"] = log_data[21]
    r["password"] = log_data[22]
    r["proxied"] = log_data[23]
    r["src_fuids"] = log_data[24]
    r["src_filenames"] = log_data[25]
    r["src_mime_types"] = log_data[26]
    r["dst_fuids"] = log_data[27]
    r["dst_filenames"] = log_data[28]
    r["dst_mime_types"] = log_data[29]
    return r

def getHttpByUid(path):
    r = Counter()
    log_file = openLogFile(path)
    for log_entry in log_file:
        try:
            log_data = parseZeekHttp(log_entry)
            r.update([log_data['uid']])
        except:
            pass
    return r

def detectBeacons(conn_path, http_path):
    req = getHttpByUid(http_path)
    conn_log = openLogFile(conn_path)
    beacons = []
    for log_entry in conn_log:
        try:
            log_data = parseZeekConn(log_entry)
            if log_data['service'] == "http":
                log_data['requests'] = req[log_data['uid']]
                beacons.append(log_data)
        except:
            pass

    # sort descending based on the number of requests
    print(beacons[:5])

    beacons.sort(key=itemgetter("requests"), reverse=True)


    # display the top beacons
    header = "{:20}\t{:5}\t{:5}".format("Dst. IP", "Duration", "Requests")
    print(header)
    print("-" * len(header))
    for entry in beacons[:8]:
        print("{:20}\t{:5}\t{:5}".format(entry['dst_ip'], entry['duration'], entry['requests']))

detectBeacons(r"log_file_analysis\logs\conn.log", r"log_file_analysis\logs\http.log")
